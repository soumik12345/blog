{
  
    
        "post0": {
            "title": "Enet-Camvid",
            "content": "Project Repository: https://github.com/soumik12345/enet . Network Architecture . import torch from torch.nn import functional as F from torch.nn import ( Module, Conv2d, ReLU, PReLU, Dropout2d, AvgPool2d, Upsample, MaxPool2d, Sequential, MaxUnpool2d, BatchNorm2d, AdaptiveAvgPool2d, ConvTranspose2d ) from IPython.display import SVG . Activation Module . Inspired by Swish Activation Function (Paper), Mish is a Self Regularized Non-Monotonic Neural Activation Function. Mish Activation Function can be mathematically represented by the following formula: . $f(x) = x * tanh(ln(1 + e^{x}))$ . It can also be represented using the Softplus Activation Function: $f(x) = x * tanh( varsigma (x))$ . where, $ varsigma (x) = ln(1 + e^{x})$ . class Mish(Module): def __init(self): super().__init__() def forward(self, input): return input * torch.tanh(F.softplus(input)) . Since Pytorch does not explicitly have any Module for Activation unlike Tensorflow, we can easily implement it. The following Module could be modified to incorporate for any number of activation functions, each of which can be accessed with a string label. . class Activation(Module): def __init__(self, name=&#39;relu&#39;): super().__init__() self.name = name if name == &#39;relu&#39;: self.act = ReLU() elif name == &#39;prelu&#39;: self.act = PReLU() elif name == &#39;mish&#39;: self.act = Mish() def forward(self, input): return self.act(input) . Enet Initial Block . The Initial Block is the first block of the Enet Model. It consists of 2 branches, a convolutional layer (out_channels=13, kernel_size=3, stride=2) which we would call the main branch in our implementation and a MaxPooling layer which is performed with non-overlapping 2x2 windows which is a secondary block. We would perform BatchNormalization and a Non-linear Activation on the concatenation of the two branches. The Input block would have 16 output channels. . SVG(&#39;enet_initial_block_xc7itf.svg&#39;) . . InputInputConvolution(13, 3x3, strides=2)Convolution&lt;br&gt;(13, 3x3, strides=2)MaxPool2dMaxPool2dBatchNorm2dBatchNorm2dActivation FunctionActivation FunctionConcatConcat class InitialBlock(Module): def __init__(self, in_channels, out_channels, bias=False, activation=&#39;relu&#39;): super().__init__() self.main_branch = Conv2d( in_channels, out_channels - 3, kernel_size=3, stride=2, padding=1, bias=bias ) self.secondary_branch = MaxPool2d(3, stride=2, padding=1) self.batch_norm = BatchNorm2d(out_channels) self.activation = Activation(activation) def forward(self, x): main = self.main_branch(x) secondary = self.secondary_branch(x) output = torch.cat((main, secondary), 1) output = self.batch_norm(output) output = self.activation(output) return output . Regular Bottleneck Block . In case of the Regular Bottleneck Block which is the most widely used block in the ENet architecture, the secondary block has no operations. The middle convolution blocks are either 3x3 regular convolutional block or a 5x5 asymmetric convolutional block. All the convolutional blocks in the main branch have Batchnormalization and respective Activation after them. The main branch is regularized by a Dropout operation. . SVG(&#39;enet_regular_bottleneck_esc4ir.svg&#39;) . . Conv 1x1Conv 1x1Conv 3x3orAsymmetric Conv 5x5Conv 3x3&lt;br&gt;or&lt;br&gt;Asymmetric Conv 5x5Conv 1x1Conv 1x1++Activation FunctionActivation Function class RegularBottleneckBlock(Module): def __init__( self, channels, internal_ratio=4, kernel_size=3, padding=0, dilation=1, asymmetric=False, dropout_prob=0, bias=False, activation=&#39;relu&#39;): super().__init__() internal_channels = channels // internal_ratio ### Main Branch ### # Block 1 Conv 1x1 self.main_conv_block_1 = Sequential( Conv2d( channels, internal_channels, kernel_size=1, stride=1, bias=bias ), BatchNorm2d(internal_channels), Activation(activation) ) # Block 2 if asymmetric: self.main_conv_block_2 = Sequential( Conv2d( internal_channels, internal_channels, kernel_size=(kernel_size, 1), stride=1, padding=(padding, 0), dilation=dilation, bias=bias ), BatchNorm2d(internal_channels), Activation(activation), Conv2d( internal_channels, internal_channels, kernel_size=(1, kernel_size), stride=1, padding=(0, padding), dilation=dilation, bias=bias ), BatchNorm2d(internal_channels), Activation(activation), ) else: self.main_conv_block_2 = Sequential( Conv2d( internal_channels, internal_channels, kernel_size=kernel_size, stride=1, padding=padding, dilation=dilation, bias=bias ), BatchNorm2d(internal_channels), Activation(activation), ) # Block 3 Conv 1x1 self.main_conv_block_3 = Sequential( Conv2d( internal_channels, channels, kernel_size=1, stride=1, bias=bias ), BatchNorm2d(channels), Activation(activation), ) # Dropout Regularization self.dropout = Dropout2d(p=dropout_prob) # Activation self.activation = Activation(activation) def forward(self, x): secondary_branch = x main_branch = self.main_conv_block_1(x) main_branch = self.main_conv_block_2(main_branch) main_branch = self.main_conv_block_3(main_branch) main_branch = self.dropout(main_branch) output = main_branch + secondary_branch output = self.activation(output) return output . Downsample Bottleneck Block . This block is used in the Encoder stages of the Enet Architecture. In this block, the main branch is Conv 1x1 -&gt; Conv 3x3 -&gt; Conv 1x1 -&gt; Dropout. The secondary branch consists of a Maxpooling operation performed with non-overlapping 2x2 windows. . SVG(&#39;enet_downsampling_bottleneck-1_ysayci.svg&#39;) . . Conv 1x1Conv 1x1Conv 3x3Conv 3x3Conv 1x1Conv 1x1++Activation FunctionActivation FunctionMaxPooling2d 2x2MaxPooling2d 2x2 class DownsampleBottleneckBlock(Module): def __init__( self, in_channels, out_channels, internal_ratio=4, return_indices=False, dropout_prob=0, bias=False, activation=&#39;relu&#39;): super().__init__() internal_channels = in_channels // internal_ratio self.return_indices = return_indices ### Main Branch ### # Block 1 Conv 1x1 self.main_conv_block_1 = Sequential( Conv2d( in_channels, internal_channels, kernel_size=2, stride=2, bias=bias ), BatchNorm2d(internal_channels), Activation(activation) ) # Block 2 Conv 3x3 self.main_conv_block_2 = Sequential( Conv2d( internal_channels, internal_channels, kernel_size=3, stride=1, padding=1, bias=bias ), BatchNorm2d(internal_channels), Activation(activation) ) # Block 2 Conv 1x1 self.main_conv_block_3 = Sequential( Conv2d( internal_channels, out_channels, kernel_size=1, stride=1, bias=bias ), BatchNorm2d(out_channels), Activation(activation) ) ### Secondary Branch ### self.secondary_maxpool = MaxPool2d( 2, stride=2, return_indices=return_indices ) # Dropout Regularization self.dropout = Dropout2d(p=dropout_prob) # Activation self.activation = Activation(activation) def forward(self, x): # Main Branch main_branch = self.main_conv_block_1(x) main_branch = self.main_conv_block_2(main_branch) main_branch = self.main_conv_block_3(main_branch) # Secondary Branch if self.return_indices: secondary_branch, max_indices = self.secondary_maxpool(x) else: secondary_branch = self.secondary_maxpool(x) # Padding n, ch_main, h, w = main_branch.size() ch_sec = secondary_branch.size()[1] padding = torch.zeros(n, ch_main - ch_sec, h, w) if secondary_branch.is_cuda: padding = padding.cuda() # Concatenate secondary_branch = torch.cat((secondary_branch, padding), 1) output = secondary_branch + main_branch output = self.activation(output) if self.return_indices: return output, max_indices else: return output . Upsampling Bottleneck Block . This block is used in the Decoder stages of the Enet Architecture. In this block, the main branch is Conv 1x1 -&gt; ConvTranspose2d 3x3 -&gt; Conv 1x1 -&gt; Dropout. The Secondary branch consists of Conv 1x1 block followed by a MaxUnpooling2d (Inverse of MaxPooling2d) Block. . SVG(&#39;enet_upsampling_block_du1lmw.svg&#39;) . . Conv 1x1Conv 1x1Conv 3x3Conv 3x3Conv 1x1Conv 1x1++Activation FunctionActivation FunctionMaxUnPooling2d2x2MaxUnPooling2d&lt;br&gt;2x2Conv 1x1Conv 1x1 class UpsampleBottleneckBlock(Module): def __init__( self, in_channels, out_channels, internal_ratio=4, dropout_prob=0, bias=False, activation=&#39;relu&#39;): super().__init__() internal_channels = in_channels // internal_ratio ### Main Branch ### # Block 1 Conv 1x1 self.main_branch_conv_1 = Sequential( Conv2d( in_channels, internal_channels, kernel_size=1, bias=bias ), BatchNorm2d(internal_channels), Activation(activation) ) # Block 2 Transposed Convolution self.main_branch_transpose_conv_2 = ConvTranspose2d( internal_channels, internal_channels, kernel_size=2, stride=2, bias=bias ) self.main_branch_bn_2 = BatchNorm2d(internal_channels) self.main_branch_act_2 = Activation(activation) # Block 3 Conv 1x1 self.main_branch_conv_3 = Sequential( Conv2d( internal_channels, out_channels, kernel_size=1, bias=bias ), BatchNorm2d(out_channels), Activation(activation) ) ### Secondary Branch ### self.secondary_conv = Sequential( Conv2d( in_channels, out_channels, kernel_size=1, bias=bias ), BatchNorm2d(out_channels) ) self.secondary_unpool = MaxUnpool2d(kernel_size=2) # Dropout Regularization self.dropout = Dropout2d(p=dropout_prob) # Activation self.activation = Activation(activation) def forward(self, x, max_indices, output_size): # Main Branch main_branch = self.main_branch_conv_1(x) main_branch = self.main_branch_transpose_conv_2(main_branch, output_size=output_size) main_branch = self.main_branch_bn_2(main_branch) main_branch = self.main_branch_act_2(main_branch) main_branch = self.main_branch_conv_3(main_branch) main_branch = self.dropout(main_branch) # Secondary Branch secondary_branch = self.secondary_conv(x) secondary_branch = self.secondary_unpool( secondary_branch, max_indices, output_size=output_size ) # Concatenate output = main_branch + secondary_branch output = self.activation(output) return output . Building Enet . The overall architecture of Enet is summarized in the following table. The whole architecture is divided into 6 parts or stages. Stage 0 consists of the Initial Block only. Stages 1-3 make up the encoder part of the network which downsamples the input. Stages 4-5 makes up the decoder, which upsamples the input to create the output. . Name Type Output Size . Initial | | 16x256x256 | . - | - | - | . Bottleneck_1 | Downsampling | 64x128x128 | . RegularBottleneck_1_1 | | 64x128x128 | . RegularBottleneck_1_2 | | 64x128x128 | . RegularBottleneck_1_3 | | 64x128x128 | . RegularBottleneck_1_4 | | 64x128x128 | . - | - | - | . Bottleneck_2 | Downsampling | 128x64x64 | . RegularBottleneck_2_1 | | 128x64x64 | . RegularBottleneck_2_2 | Dilated 2 | 128x64x64 | . RegularBottleneck_2_3 | Asymmetric 5 | 128x64x64 | . RegularBottleneck_2_4 | Dilated 4 | 128x64x64 | . RegularBottleneck_2_5 | | 128x64x64 | . RegularBottleneck_2_6 | Dilated 8 | 128x64x64 | . RegularBottleneck_2_7 | Asymmetric 5 | 128x64x64 | . RegularBottleneck_2_8 | Dilated 16 | 128x64x64 | . - | - | - | . RegularBottleneck_3 | | 128x64x64 | . RegularBottleneck_3_1 | Dilated 2 | 128x64x64 | . RegularBottleneck_3_2 | Assymetric 5 | 128x64x64 | . RegularBottleneck_3_3 | Dilated 4 | 128x64x64 | . RegularBottleneck_3_4 | | 128x64x64 | . RegularBottleneck_3_5 | Dilated 8 | 128x64x64 | . RegularBottleneck_3_6 | Asymmetric 5 | 128x64x64 | . RegularBottleneck_3_7 | Dilated 16 | 128x64x64 | . - | - | - | . Bottleneck_4 | Upsampling | 64x128x128 | . Bottleneck_4_1 | | 64x128x128 | . Bottleneck_4_2 | | 64x128x128 | . - | - | - | . Bottleneck_5 | Upsampling | 16x256x256 | . Bottleneck_5_1 | | 16x256x256 | . - | - | - | . Transposed_Conv | | Cx512x512 | . class Enet(Module): def __init__(self, num_classes, encoder_activation=&#39;mish&#39;, decoder_activation=&#39;relu&#39;): super().__init__() # Initial Block self.initial_block = InitialBlock(3, 16, activation=encoder_activation) ### Encoding Stages ### # Stage 1 self.down_bottleneck_1 = DownsampleBottleneckBlock( 16, 64, return_indices=True, dropout_prob=0.01, activation=encoder_activation ) self.bottleneck_1_1 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.01, activation=encoder_activation ) self.bottleneck_1_2 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.01, activation=encoder_activation ) self.bottleneck_1_3 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.01, activation=encoder_activation ) self.bottleneck_1_4 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.01, activation=encoder_activation ) # Stage 2 self.down_bottleneck_2 = DownsampleBottleneckBlock( 64, 128, return_indices=True, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_1 = RegularBottleneckBlock( 128, padding=1, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_2 = RegularBottleneckBlock( 128, dilation=2, padding=2, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_3 = RegularBottleneckBlock( 128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_4 = RegularBottleneckBlock( 128, dilation=4, padding=4, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_5 = RegularBottleneckBlock( 128, padding=1, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_6 = RegularBottleneckBlock( 128, dilation=8, padding=8, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_7 = RegularBottleneckBlock( 128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_2_8 = RegularBottleneckBlock( 128, dilation=16, padding=16, dropout_prob=0.1, activation=encoder_activation ) # Stage 3 self.regular_bottleneck_3 = RegularBottleneckBlock( 128, padding=1, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_1 = RegularBottleneckBlock( 128, dilation=2, padding=2, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_2 = RegularBottleneckBlock( 128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_3 = RegularBottleneckBlock( 128, dilation=4, padding=4, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_4 = RegularBottleneckBlock( 128, padding=1, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_5 = RegularBottleneckBlock( 128, dilation=8, padding=8, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_6 = RegularBottleneckBlock( 128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, activation=encoder_activation ) self.bottleneck_3_7 = RegularBottleneckBlock( 128, dilation=16, padding=16, dropout_prob=0.1, activation=encoder_activation ) # Stage 4 self.upsample_4 = UpsampleBottleneckBlock( 128, 64, dropout_prob=0.1, activation=decoder_activation ) self.bottleneck_4_1 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.1, activation=decoder_activation ) self.bottleneck_4_2 = RegularBottleneckBlock( 64, padding=1, dropout_prob=0.1, activation=decoder_activation ) # Stage 5 self.upsample_5 = UpsampleBottleneckBlock( 64, 16, dropout_prob=0.1, activation=decoder_activation ) self.bottleneck_5 = RegularBottleneckBlock( 16, padding=1, dropout_prob=0.1, activation=decoder_activation ) self.transposed_conv = ConvTranspose2d( 16, num_classes, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False ) def forward(self, x): # Initial Block input_size = x.size() x = self.initial_block(x) # Stage 1 input_size_1 = x.size() x, max_indices_1 = self.down_bottleneck_1(x) x = self.bottleneck_1_1(x) x = self.bottleneck_1_2(x) x = self.bottleneck_1_3(x) x = self.bottleneck_1_4(x) # Stage 2 input_size_2 = x.size() x, max_indices_2 = self.down_bottleneck_2(x) x = self.bottleneck_2_1(x) x = self.bottleneck_2_2(x) x = self.bottleneck_2_3(x) x = self.bottleneck_2_4(x) x = self.bottleneck_2_5(x) x = self.bottleneck_2_6(x) x = self.bottleneck_2_7(x) x = self.bottleneck_2_8(x) # Stage 3 x = self.regular_bottleneck_3(x) x = self.bottleneck_3_1(x) x = self.bottleneck_3_2(x) x = self.bottleneck_3_3(x) x = self.bottleneck_3_4(x) x = self.bottleneck_3_5(x) x = self.bottleneck_3_6(x) x = self.bottleneck_3_7(x) # Stage 4 x = self.upsample_4(x, max_indices_2, output_size=input_size_2) x = self.bottleneck_4_1(x) x = self.bottleneck_4_2(x) # Stage 5 x = self.upsample_5(x, max_indices_1, output_size=input_size_1) x = self.bottleneck_5(x) x = self.transposed_conv(x) return x . print(&#39;GPU:&#39;, torch.cuda.get_device_name(0)) device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;) enet = Enet(12, encoder_activation=&#39;prelu&#39;, decoder_activation=&#39;relu&#39;) enet = enet.to(device) print(enet) . GPU: Quadro P5000 Enet( (initial_block): InitialBlock( (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (secondary_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (down_bottleneck_1): DownsampleBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (secondary_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.01, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_1_1): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.01, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_1_2): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.01, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_1_3): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.01, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_1_4): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.01, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (down_bottleneck_2): DownsampleBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (secondary_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_1): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_2): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_3): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False) (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_4): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_5): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_6): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_7): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False) (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_2_8): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (regular_bottleneck_3): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_1): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_2): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False) (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_3): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_4): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_5): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_6): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False) (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (bottleneck_3_7): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_2): Sequential( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (main_conv_block_3): Sequential( (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): PReLU(num_parameters=1) ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): PReLU(num_parameters=1) ) ) (upsample_4): UpsampleBottleneckBlock( (main_branch_conv_1): Sequential( (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_branch_transpose_conv_2): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False) (main_branch_bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (main_branch_act_2): Activation( (act): ReLU() ) (main_branch_conv_3): Sequential( (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (secondary_conv): Sequential( (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (secondary_unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): ReLU() ) ) (bottleneck_4_1): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): ReLU() ) ) (bottleneck_4_2): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_2): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_3): Sequential( (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): ReLU() ) ) (upsample_5): UpsampleBottleneckBlock( (main_branch_conv_1): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_branch_transpose_conv_2): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False) (main_branch_bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (main_branch_act_2): Activation( (act): ReLU() ) (main_branch_conv_3): Sequential( (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (secondary_conv): Sequential( (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (secondary_unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0)) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): ReLU() ) ) (bottleneck_5): RegularBottleneckBlock( (main_conv_block_1): Sequential( (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_2): Sequential( (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (main_conv_block_3): Sequential( (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): Activation( (act): ReLU() ) ) (dropout): Dropout2d(p=0.1, inplace=False) (activation): Activation( (act): ReLU() ) ) (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False) ) . Pipeline for Camvid Dataset . Download Dataset . !mkdir camvid %cd camvid !wget https://www.dropbox.com/s/ej1gx48bxqbtwd2/CamVid.zip?dl=0 -O CamVid.zip !unzip -qq CamVid.zip !rm CamVid.zip %cd .. . /notebooks/camvid --2019-12-22 17:08:27-- https://www.dropbox.com/s/ej1gx48bxqbtwd2/CamVid.zip?dl=0 Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.1, 2620:100:601a:1::a27d:701 Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.1|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: /s/raw/ej1gx48bxqbtwd2/CamVid.zip [following] --2019-12-22 17:08:27-- https://www.dropbox.com/s/raw/ej1gx48bxqbtwd2/CamVid.zip Reusing existing connection to www.dropbox.com:443. HTTP request sent, awaiting response... 302 Found Location: https://uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com/cd/0/inline/Auv6VxzcBuE4iS57nb8ME8vAwaN4ktj3ntJn3Sfvu9OVl8uIdY83BB2uBh2hpf2XOGPfSPccgOW5ngRb-3iOMV-CouNNKyCf0wsmWSv5zvU6m3zieRaW9-IfjCJzpJd2ZYY/file# [following] --2019-12-22 17:08:27-- https://uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com/cd/0/inline/Auv6VxzcBuE4iS57nb8ME8vAwaN4ktj3ntJn3Sfvu9OVl8uIdY83BB2uBh2hpf2XOGPfSPccgOW5ngRb-3iOMV-CouNNKyCf0wsmWSv5zvU6m3zieRaW9-IfjCJzpJd2ZYY/file Resolving uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com (uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com)... 162.125.7.6, 2620:100:601a:6::a27d:706 Connecting to uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com (uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com)|162.125.7.6|:443... connected. HTTP request sent, awaiting response... 302 FOUND Location: /cd/0/inline2/Auv2moV75j6bD1ZVWnQ8TzgrCT8YBavOXNvuI93KzHABa5foU5NHalPz2iQVfVIxJqmlUNryF9fCadSY8v0pFlH56XP593-KMVw74ZrrfGxJx7cylo6nofaqbN6VgrPRTVrHRCmsZN5jvmf_tjdUSF3AbS5eYHVZFyJk7hjbVMW4nOEc2R5qNXUtHfBhgNnPVALcCzygAzHAPG85VZPW-lEbnVPgCybPUM-cNsxBEKOGQJtGIAAelpJyJpppUuIIr3hgXBHKLylw-29RpcKkeADZ3MJHzAIEnXehRGlzhe7aYzWquPr6-Pqi82AWy9sieCEC2m8xAWKZgpWG7Vw5-F1LZpihT2zqET2lfb6JtpP4bg/file [following] --2019-12-22 17:08:28-- https://uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com/cd/0/inline2/Auv2moV75j6bD1ZVWnQ8TzgrCT8YBavOXNvuI93KzHABa5foU5NHalPz2iQVfVIxJqmlUNryF9fCadSY8v0pFlH56XP593-KMVw74ZrrfGxJx7cylo6nofaqbN6VgrPRTVrHRCmsZN5jvmf_tjdUSF3AbS5eYHVZFyJk7hjbVMW4nOEc2R5qNXUtHfBhgNnPVALcCzygAzHAPG85VZPW-lEbnVPgCybPUM-cNsxBEKOGQJtGIAAelpJyJpppUuIIr3hgXBHKLylw-29RpcKkeADZ3MJHzAIEnXehRGlzhe7aYzWquPr6-Pqi82AWy9sieCEC2m8xAWKZgpWG7Vw5-F1LZpihT2zqET2lfb6JtpP4bg/file Reusing existing connection to uc5e0c03b1fd422e4efdf9b56c46.dl.dropboxusercontent.com:443. HTTP request sent, awaiting response... 200 OK Length: 187049523 (178M) [application/zip] Saving to: ‘CamVid.zip’ CamVid.zip 100%[===================&gt;] 178.38M 25.0MB/s in 8.3s 2019-12-22 17:08:37 (21.5 MB/s) - ‘CamVid.zip’ saved [187049523/187049523] /notebooks . import numpy as np import torch, os from glob import glob from time import time from tqdm import tqdm from PIL import Image from torch.nn import functional as F from matplotlib import pyplot as plt from torch.utils.data import Dataset from torch.utils.data import DataLoader from torchvision.transforms import ToTensor, ToPILImage . Dataset Pipeline . Camvid Dataset . The CamVidDataset characterizes the key features of the dataset that we want to generate on the fly. inherits from torch.utils.data.Dataset in order to leverage the multiprocessing functionalities of Pytorch. . class CamVidDataset(Dataset): def __init__(self, images, labels, height, width): self.images = images self.labels = labels self.height = height self.width = width def __len__(self): return len(self.images) def __getitem__(self, index): image_id = self.images[index] label_id = self.labels[index] # Read Image x = Image.open(image_id) x = [np.array(x)] x = np.stack(x, axis=2) x = torch.tensor(x).transpose(0, 2).transpose(1, 3) # Convert to N, C, H, W # Read Mask y = Image.open(label_id) y = [np.array(y)] y = torch.tensor(y) return x.squeeze(), y.squeeze() . Get the image file lists . train_images = sorted(glob(&#39;./camvid/train/*&#39;)) train_labels = sorted(glob(&#39;./camvid/trainannot/*&#39;)) val_images = sorted(glob(&#39;./camvid/val/*&#39;)) val_labels = sorted(glob(&#39;./camvid/valannot/*&#39;)) test_images = sorted(glob(&#39;./camvid/test/*&#39;)) test_labels = sorted(glob(&#39;./camvid/testannot/*&#39;)) batch_size = 10 . Define the CamVidDataset Objects . train_dataset = CamVidDataset(train_images, train_labels, 512, 512) val_dataset = CamVidDataset(val_images, val_labels, 512, 512) test_dataset = CamVidDataset(test_images, test_labels, 512, 512) . Now we would create the DataLoader objects which would generate data from the dataset objects. The arguments that we would set here are: . batch_size: this denotes the number of samples contained in each generated batch. | shuffle: If set to True, we will get a new order of exploration at each pass (or just keep a linear exploration scheme otherwise). Shuffling the order in which examples are fed to the classifier is helpful so that batches between epochs do not look alike. Doing so will eventually make our model more robust. | num_workers: this denotes the number of processes that generate batches in parallel. A high enough number of workers assures that CPU computations are efficiently managed, i.e. that the bottleneck is indeed the neural network&#39;s forward and backward operations on the GPU (and not data generation). | . train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4) . The decode_segmap function accepts an image of shape (H, W) and a color dictionary denoting the BGR color codes to various objects in order for us to visualize the segmentation Masks. . def decode_segmap(image, color_dict): label_colours = np.array([ color_dict[&#39;obj0&#39;], color_dict[&#39;obj1&#39;], color_dict[&#39;obj2&#39;], color_dict[&#39;obj3&#39;], color_dict[&#39;obj4&#39;], color_dict[&#39;obj5&#39;], color_dict[&#39;obj6&#39;], color_dict[&#39;obj7&#39;], color_dict[&#39;obj8&#39;], color_dict[&#39;obj9&#39;], color_dict[&#39;obj10&#39;], color_dict[&#39;obj11&#39;] ]).astype(np.uint8) r = np.zeros_like(image).astype(np.uint8) g = np.zeros_like(image).astype(np.uint8) b = np.zeros_like(image).astype(np.uint8) for l in range(0, 12): r[image == l] = label_colours[l, 0] g[image == l] = label_colours[l, 1] b[image == l] = label_colours[l, 2] rgb = np.zeros((image.shape[0], image.shape[1], 3)).astype(np.uint8) rgb[:, :, 0] = b rgb[:, :, 1] = g rgb[:, :, 2] = r return rgb . The predict_rgb function takes the model(enet in our case), a tensor denoting a single image in the form (1, C, H, W) and the color_dict and gives us the visualizable prediction . def predict_rgb(model, tensor, color_dict): with torch.no_grad(): out = model(tensor.float()).squeeze(0) out = out.data.max(0)[1].cpu().numpy() return decode_segmap(out, color_dict) . The color_dict is a dictionary where each object is mapped to its respective color code. . color_dict = { &#39;obj0&#39; : [255, 0, 0], # Sky &#39;obj1&#39; : [0, 51, 204], # Building &#39;obj2&#39; : [0, 255, 255], # Posts &#39;obj3&#39; : [153, 102, 102], # Road &#39;obj4&#39; : [51, 0, 102], # Pavement &#39;obj5&#39; : [0, 255, 0], # Trees &#39;obj6&#39; : [102, 153, 153], # Signs &#39;obj7&#39; : [204, 0, 102], # Fence &#39;obj8&#39; : [102, 0, 0], # Car &#39;obj9&#39; : [0, 153, 102], # Pedestrian &#39;obj10&#39; : [255, 255, 255], # Cyclist &#39;obj11&#39; : [0, 0, 0] # bicycles } . Let us generate a batch from the train dataloader and visualize them along with their prediction using an untrained Enet. . x_batch, y_batch = next(iter(train_loader)) x_batch.shape, y_batch.shape . (torch.Size([10, 3, 360, 480]), torch.Size([10, 360, 480])) . fig, axes = plt.subplots(nrows = 4, ncols = 3, figsize = (16, 16)) plt.setp(axes.flat, xticks = [], yticks = []) c = 1 for i, ax in enumerate(axes.flat): if i % 3 == 0: ax.imshow(ToPILImage()(x_batch[c])) ax.set_xlabel(&#39;Image_&#39; + str(c)) elif i % 3 == 1: ax.imshow(decode_segmap(y_batch[c], color_dict)) ax.set_xlabel(&#39;Ground_Truth_&#39; + str(c)) elif i % 3 == 2: ax.imshow(predict_rgb(enet, x_batch[c].unsqueeze(0).to(device), color_dict)) ax.set_xlabel(&#39;Predicted_Mask_&#39; + str(c)) c += 1 plt.show() . Training . from torch.optim import Adam from torch.nn import CrossEntropyLoss . The authors make use of a custom class weighing scheme defined as $w_{class} = frac{1}{ln(c + p_{class})}$, where c is an additional hyper-parameter set to 1.02. The advantage of this weighing strategy is that in contrast to the inverse class probability weighing strategy, the weights are bounded as the probability approaches 0. . def get_class_weights(loader, num_classes, c=1.02): _, y= next(iter(loader)) y_flat = y.flatten() each_class = np.bincount(y_flat, minlength=num_classes) p_class = each_class / len(y_flat) return 1 / (np.log(c + p_class)) . Now, we will set up the Criterion and Optimizer. The learning rate is set to 5e-4 with a weight decay of 2e-4 as mentioned in the paper. . class_weights = get_class_weights(train_loader, 12) criterion = CrossEntropyLoss( weight=torch.FloatTensor(class_weights).to(device) ) optimizer = Adam( enet.parameters(), lr=5e-4, weight_decay=2e-4 ) . Next, we implement the training procedure: . We first loop over the Main Training Loop for a particular number of epochs. | For each epoch, we loop over the dataset for a particular number of steps which is equal to length of dataset // batch_size. This is to ensure that the model gets a chance to look at most of the images in a single epoch. | In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. | Perform Backpropagation. | Store the training loss. | Log the traning results (optional). | Perform Validation using the validation dataloader. | Log the validation results (optional). | Save the model states and results after several epochs (optional). | def train( model, train_dataloader, val_dataloader, device, criterion, optimizer, train_step_size, val_step_size, visualize_every, save_every, save_location, save_prefix, epochs): # Make sure that the checkpoint location exists try: os.mkdir(save_location) except: pass train_loss_history, val_loss_history = [], [] # Training for epoch in range(1, epochs + 1): print(&#39;Epoch {} n&#39;.format(epoch)) # Training start = time() train_loss = 0 model.train() # Step Loop for step in tqdm(range(train_step_size)): x_batch, y_batch = next(iter(train_dataloader)) x_batch = x_batch.squeeze().to(device) y_batch = y_batch.squeeze().to(device) optimizer.zero_grad() out = model(x_batch.float()) loss = criterion(out, y_batch.long()) loss.backward() optimizer.step() train_loss += loss.item() train_loss_history.append(train_loss / train_step_size) print(&#39; nTraining Loss: {}&#39;.format(train_loss_history[-1])) print(&#39;Training Time: {} seconds&#39;.format(time() - start)) # Validation val_loss = 0 model.eval() for step in tqdm(range(val_step_size)): x_val, y_val = next(iter(val_dataloader)) x_val = x_val.squeeze().to(device) y_val = y_val.squeeze().to(device) out = model(x_val.float()) out = out.data.max(1)[1] val_loss += (y_val.long() - out.long()).float().mean() val_loss_history.append(val_loss) print(&#39; nValidation Loss: {}&#39;.format(val_loss)) # Visualization if epoch % visualize_every == 0: x_batch, y_batch = next(iter(train_loader)) fig, axes = plt.subplots(nrows = 4, ncols = 3, figsize = (16, 16)) plt.setp(axes.flat, xticks = [], yticks = []) c = 1 for i, ax in enumerate(axes.flat): if i % 3 == 0: ax.imshow(ToPILImage()(x_batch[c])) ax.set_xlabel(&#39;Image_&#39; + str(c)) elif i % 3 == 1: ax.imshow(decode_segmap(y_batch[c], color_dict)) ax.set_xlabel(&#39;Ground_Truth_&#39; + str(c)) elif i % 3 == 2: ax.imshow(predict_rgb(enet, x_batch[c].unsqueeze(0).to(device), color_dict)) ax.set_xlabel(&#39;Predicted_Mask_&#39; + str(c)) c += 1 plt.show() # Checkpoints if epoch % save_every == 0: checkpoint = { &#39;epoch&#39; : epoch, &#39;train_loss&#39; : train_loss, &#39;val_loss&#39; : val_loss, &#39;state_dict&#39; : model.state_dict() } torch.save( checkpoint, &#39;{}/{}-{}-{}-{}.pth&#39;.format( save_location, save_prefix, epoch, train_loss, val_loss ) ) print(&#39;Checkpoint saved&#39;) print( &#39; nTraining Done. nTraining Mean Loss: {:6f} nValidation Mean Loss: {:6f}&#39;.format( sum(train_loss_history) / epochs, sum(val_loss_history) / epochs ) ) return train_loss_history, val_loss_history . train_loss_history, val_loss_history = train( enet, train_loader, val_loader, device, criterion, optimizer, len(train_images) // batch_size, len(val_images) // batch_size, 5, 5, &#39;./checkpoints&#39;, &#39;enet-model&#39;, 100 ) . 0%| | 0/36 [00:00&lt;?, ?it/s] . Epoch 1 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 2.3736738430129156 Training Time: 36.622546672821045 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.29it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: 2.495696544647217 Epoch 2 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 2.066100193394555 Training Time: 37.32582426071167 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: 1.0354421138763428 Epoch 3 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.819241699245241 Training Time: 37.225857734680176 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.32it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.462801933288574 Epoch 4 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.6384391950236425 Training Time: 37.67400813102722 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.796051502227783 Epoch 5 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.5421283278200362 Training Time: 37.320696115493774 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] . Validation Loss: -4.719521522521973 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 6 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.4267812801731958 Training Time: 36.2429084777832 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.382036209106445 Epoch 7 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.3556759390566084 Training Time: 37.677775144577026 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.395351886749268 Epoch 8 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.3103740215301514 Training Time: 37.39039158821106 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.13it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.370512008666992 Epoch 9 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.2682642042636871 Training Time: 37.26855731010437 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -8.429301261901855 Epoch 10 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.2029826508627997 Training Time: 37.28497934341431 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] . Validation Loss: -6.792354106903076 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 11 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.1570831570360396 Training Time: 37.477909326553345 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.195928573608398 Epoch 12 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.1395491758982341 Training Time: 37.90213441848755 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.173197269439697 Epoch 13 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.1266514195336237 Training Time: 37.404568910598755 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.15it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.771578311920166 Epoch 14 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.0894614275958803 Training Time: 37.46945667266846 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.576180934906006 Epoch 15 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.0793888171513875 Training Time: 36.50749087333679 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.22it/s] . Validation Loss: -6.073637962341309 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 16 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.0256218943330977 Training Time: 37.52659511566162 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.31it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -8.707944869995117 Epoch 17 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.0208994067377515 Training Time: 37.60098838806152 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.22it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.784101963043213 Epoch 18 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 1.00802077849706 Training Time: 37.67285490036011 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -8.1976957321167 Epoch 19 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.9760349442561468 Training Time: 37.02203035354614 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.21it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.932909965515137 Epoch 20 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.9686084638039271 Training Time: 36.49009346961975 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.28it/s] . Validation Loss: -10.035560607910156 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 21 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.9232347259918848 Training Time: 36.40699481964111 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.17it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.618765830993652 Epoch 22 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.9214804338084327 Training Time: 37.64718818664551 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.437498569488525 Epoch 23 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.8775700446632173 Training Time: 36.491459608078 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.585930824279785 Epoch 24 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.8676599446270201 Training Time: 37.75159788131714 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.16it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.8291826248168945 Epoch 25 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.8542953348822064 Training Time: 38.35563540458679 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] . Validation Loss: -10.226922988891602 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 26 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.00s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.8472818914386961 Training Time: 36.00928783416748 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -8.36304759979248 Epoch 27 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.821869295504358 Training Time: 36.77352595329285 seconds . 100%|██████████| 10/10 [00:09&lt;00:00, 1.10it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -9.58829402923584 Epoch 28 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.7889702585008409 Training Time: 38.61393928527832 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.21it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.412705421447754 Epoch 29 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.7545491208632787 Training Time: 38.38607335090637 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.20it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -8.005655288696289 Epoch 30 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.7702976332770454 Training Time: 36.71100616455078 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] . Validation Loss: -4.231881141662598 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 31 . 100%|██████████| 36/36 [00:35&lt;00:00, 1.00it/s] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.7379177262385687 Training Time: 35.90049076080322 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.388115406036377 Epoch 32 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.7093521191014184 Training Time: 37.23017859458923 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.115187168121338 Epoch 33 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6929942336347368 Training Time: 38.1418399810791 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.22it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.854228496551514 Epoch 34 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6660703635878034 Training Time: 38.218461751937866 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.8958330154418945 Epoch 35 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6632857289579179 Training Time: 37.43135929107666 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] . Validation Loss: -5.267255783081055 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 36 . 100%|██████████| 36/36 [00:39&lt;00:00, 1.10s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6700823141468896 Training Time: 39.75525879859924 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.15it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.932151794433594 Epoch 37 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6306778772009743 Training Time: 37.12487030029297 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.28it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.434138774871826 Epoch 38 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6451671355300479 Training Time: 36.77497148513794 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.195463180541992 Epoch 39 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6210144890679253 Training Time: 37.950018882751465 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.12it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.6000566482543945 Epoch 40 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.6190666158994039 Training Time: 38.053221702575684 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.21it/s] . Validation Loss: -5.544920444488525 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 41 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5928388577368524 Training Time: 37.63972759246826 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.879909992218018 Epoch 42 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5870317411091592 Training Time: 37.024226903915405 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.742264270782471 Epoch 43 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5675398872958289 Training Time: 37.81453609466553 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.20it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.535061359405518 Epoch 44 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5501133882337146 Training Time: 36.879273414611816 seconds . 100%|██████████| 10/10 [00:09&lt;00:00, 1.11it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.253548622131348 Epoch 45 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5503247496154573 Training Time: 37.58225345611572 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.22it/s] . Validation Loss: -5.902456283569336 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 46 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5512463673949242 Training Time: 36.606677532196045 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.735024452209473 Epoch 47 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.544807703130775 Training Time: 38.517911434173584 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.32it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.34906005859375 Epoch 48 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5279948107070394 Training Time: 36.94304895401001 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.252256393432617 Epoch 49 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5191673007276323 Training Time: 37.99461269378662 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.14it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.820833206176758 Epoch 50 . 100%|██████████| 36/36 [00:39&lt;00:00, 1.09s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.49875519176324207 Training Time: 39.174588203430176 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] . Validation Loss: -4.738555431365967 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 51 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5172228713830312 Training Time: 37.38908004760742 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.111539840698242 Epoch 52 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5180092445678182 Training Time: 37.96890068054199 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.20it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -7.410361289978027 Epoch 53 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.5053947452041838 Training Time: 38.50911474227905 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.627304553985596 Epoch 54 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4888179575403531 Training Time: 38.64139103889465 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.16it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.422050952911377 Epoch 55 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4791935044858191 Training Time: 37.589763879776 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] . Validation Loss: -5.576418876647949 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 56 . 100%|██████████| 36/36 [00:40&lt;00:00, 1.12s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.45455337150229347 Training Time: 40.3157172203064 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.17it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.987201690673828 Epoch 57 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4661391567852762 Training Time: 36.715943336486816 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.11it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.632068157196045 Epoch 58 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4665369697742992 Training Time: 36.19537806510925 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.786327838897705 Epoch 59 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.45907818608813816 Training Time: 38.01468300819397 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.21it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -6.478023529052734 Epoch 60 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4500412220756213 Training Time: 37.21549987792969 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] . Validation Loss: -5.177182674407959 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 61 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.08s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.45753948307699627 Training Time: 38.74998998641968 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.29it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.799277305603027 Epoch 62 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.42691650407181847 Training Time: 37.344823598861694 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.22it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.130724906921387 Epoch 63 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4300544717245632 Training Time: 37.420971632003784 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.21it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.042947769165039 Epoch 64 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.42879077792167664 Training Time: 37.66694641113281 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.12it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.180288314819336 Epoch 65 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4272735383775499 Training Time: 37.58568787574768 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.25it/s] . Validation Loss: -4.429321765899658 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 66 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.42417974604500663 Training Time: 37.05702567100525 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.533682346343994 Epoch 67 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4159412756562233 Training Time: 37.56980299949646 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.018970012664795 Epoch 68 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.4148317939705319 Training Time: 37.138564348220825 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.9047155380249023 Epoch 69 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3963303491473198 Training Time: 37.7933931350708 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.28it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.635763168334961 Epoch 70 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.40438303930891883 Training Time: 37.2310631275177 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.16it/s] . Validation Loss: -4.414734363555908 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 71 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.39953534967369503 Training Time: 36.96225690841675 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.7862653732299805 Epoch 72 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.08s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.39342257877190906 Training Time: 38.77004361152649 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.25it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.276852130889893 Epoch 73 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3897610389524036 Training Time: 38.38589859008789 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.030964374542236 Epoch 74 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.405379969212744 Training Time: 36.81379222869873 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.7940850257873535 Epoch 75 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.377888491584195 Training Time: 37.3532612323761 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.14it/s] . Validation Loss: -3.9622135162353516 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 76 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.37682998263173634 Training Time: 36.6818642616272 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -5.148308753967285 Epoch 77 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.371006368762917 Training Time: 38.503026723861694 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.27it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.861609935760498 Epoch 78 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3602796254886521 Training Time: 38.01511263847351 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.9753198623657227 Epoch 79 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3653753134939406 Training Time: 37.917211055755615 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -2.8377439975738525 Epoch 80 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.37505776186784107 Training Time: 38.310165882110596 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] . Validation Loss: -5.334249973297119 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 81 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.36951222353511387 Training Time: 38.20164632797241 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.66939640045166 Epoch 82 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.35576848520172966 Training Time: 37.462151527404785 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.722535610198975 Epoch 83 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.36002279900842243 Training Time: 37.20385551452637 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.17it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.74808406829834 Epoch 84 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.06s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3489703999625312 Training Time: 38.138071060180664 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.982658386230469 Epoch 85 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.34990982214609784 Training Time: 37.759665727615356 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.28it/s] . Validation Loss: -4.157069683074951 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 86 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.35239921179082656 Training Time: 37.88401412963867 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.18it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.5902533531188965 Epoch 87 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.34805963353978264 Training Time: 37.58679533004761 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.319746971130371 Epoch 88 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3448881424135632 Training Time: 37.084150552749634 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.20it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.250303268432617 Epoch 89 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3393386834197574 Training Time: 38.44252109527588 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.880829334259033 Epoch 90 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3295273143384192 Training Time: 37.59496545791626 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] . Validation Loss: -4.594930648803711 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 91 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3464961921175321 Training Time: 36.96203589439392 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.14it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.407609224319458 Epoch 92 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.34060925907558864 Training Time: 38.37405014038086 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.496046543121338 Epoch 93 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.01s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3336273547675874 Training Time: 36.53633213043213 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.23it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -2.9917984008789062 Epoch 94 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3360065817832947 Training Time: 37.400681495666504 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.17it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.259033679962158 Epoch 95 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.33179697228802574 Training Time: 37.88106441497803 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.15it/s] . Validation Loss: -6.045409202575684 . . 0%| | 0/36 [00:00&lt;?, ?it/s] . Checkpoint saved Epoch 96 . 100%|██████████| 36/36 [00:38&lt;00:00, 1.07s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.329134587612417 Training Time: 38.55759382247925 seconds . 100%|██████████| 10/10 [00:07&lt;00:00, 1.26it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.940917015075684 Epoch 97 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.03s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3220530201991399 Training Time: 37.08751201629639 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -4.636651992797852 Epoch 98 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.05s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.31848980320824516 Training Time: 37.68484568595886 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.14it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -2.7739005088806152 Epoch 99 . 100%|██████████| 36/36 [00:37&lt;00:00, 1.04s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.32071789933575523 Training Time: 37.38284635543823 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.24it/s] 0%| | 0/36 [00:00&lt;?, ?it/s] . Validation Loss: -3.3696560859680176 Epoch 100 . 100%|██████████| 36/36 [00:36&lt;00:00, 1.02s/it] 0%| | 0/10 [00:00&lt;?, ?it/s] . Training Loss: 0.3072536442842748 Training Time: 36.655545473098755 seconds . 100%|██████████| 10/10 [00:08&lt;00:00, 1.19it/s] . Validation Loss: -3.19159197807312 . . Checkpoint saved Training Done. Training Mean Loss: 0.667980 Validation Mean Loss: -5.383368 . Now, let us visualize the results... . plt.plot(train_loss_history, color = &#39;b&#39;, label = &#39;Training Loss&#39;) plt.plot(val_loss_history, color = &#39;r&#39;, label = &#39;Validation Loss&#39;) plt.legend() plt.show() . plt.plot(train_loss_history, color = &#39;b&#39;, label = &#39;Training Loss&#39;) plt.legend() plt.show() . plt.plot(val_loss_history, color = &#39;r&#39;, label = &#39;Validation Loss&#39;) plt.legend() plt.show() . Prediction . We will be predicting with the weights at epoch 65 where both training and validation loss seems to be stable. This is done in order to avoid overfitting. . state_dict = torch.load(&#39;./checkpoints/enet-model-65-14.726004391908646--3.9436190128326416.pth&#39;)[&#39;state_dict&#39;] enet.load_state_dict(state_dict) . &lt;All keys matched successfully&gt; . Prediction on Training Data . x_batch, y_batch = next(iter(train_loader)) fig, axes = plt.subplots(nrows = 4, ncols = 3, figsize = (16, 16)) plt.setp(axes.flat, xticks = [], yticks = []) c = 1 for i, ax in enumerate(axes.flat): if i % 3 == 0: ax.imshow(ToPILImage()(x_batch[c])) ax.set_xlabel(&#39;Image_&#39; + str(c)) elif i % 3 == 1: ax.imshow(decode_segmap(y_batch[c], color_dict)) ax.set_xlabel(&#39;Ground_Truth_&#39; + str(c)) elif i % 3 == 2: ax.imshow(predict_rgb(enet, x_batch[c].unsqueeze(0).to(device), color_dict)) ax.set_xlabel(&#39;Predicted_Mask_&#39; + str(c)) c += 1 plt.show() . Prediction on Validation Data . x_batch, y_batch = next(iter(val_loader)) fig, axes = plt.subplots(nrows = 4, ncols = 3, figsize = (16, 16)) plt.setp(axes.flat, xticks = [], yticks = []) c = 1 for i, ax in enumerate(axes.flat): if i % 3 == 0: ax.imshow(ToPILImage()(x_batch[c])) ax.set_xlabel(&#39;Image_&#39; + str(c)) elif i % 3 == 1: ax.imshow(decode_segmap(y_batch[c], color_dict)) ax.set_xlabel(&#39;Ground_Truth_&#39; + str(c)) elif i % 3 == 2: ax.imshow(predict_rgb(enet, x_batch[c].unsqueeze(0).to(device), color_dict)) ax.set_xlabel(&#39;Predicted_Mask_&#39; + str(c)) c += 1 plt.show() .",
            "url": "https://soumik12345.github.io/blog/computervision/deeplearning/pytorch/segmentation/2020/05/05/enet-camvid.html",
            "relUrl": "/computervision/deeplearning/pytorch/segmentation/2020/05/05/enet-camvid.html",
            "date": " • May 5, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://soumik12345.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Depthwise Separable Convolutions in Deep Learning",
            "content": "The Convolution operation is a widely used function in Functional Analysis, Image Processing Deep Learning. The convolution operation when applied on two functions f and g, produces a third function expressing how the shape of one is modified by the other. While it is immensely popular, especially in the domain of Deep Learning, the vanilla convolution operation is quite expensive computationally. Modern Neural Network architectures such as Xception and MobileNet use a special type of Convolution called Depthwise Separable Convolution to speed up training and inference, especially on Mobile and Embedded Devices. . The Vanilla Convolution Operation . The convolution function can be mathematically defined as the following: . (f⊛g)(t)=∫−∞∞f(τ)g(t−τ)dτ(f circledast g)(t) = int_{- infty}^{ infty} f( tau) g(t - tau) d tau(f⊛g)(t)=∫−∞∞​f(τ)g(t−τ)dτ . For all non-negative values of t (i.e, for all values of t such that t ∈ [0, ∞) ), we could truncate the limits of integration resulting in, . (f⊛g)(t)=∫0tf(τ)g(t−τ)dτ(f circledast g)(t) = int_{0}^{t} f( tau) g(t - tau) d tau(f⊛g)(t)=∫0t​f(τ)g(t−τ)dτ . It can also be defined as the overlap of two functions f and g as one slides over the other, performing a sum of products. . Source: https://en.wikipedia.org/wiki/Convolution Convolution as Sum of Products. Source: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1 Computational Complexity of Convolution . In order to decide the computational complexity of the convolutional operation, we would count the number of multiplication operations for a convolution. This is because the Binary Addition of two numbers may be performed in a single clock cycle using two registers with the inputs latched and a bunch of combinatorial logic gates. Binary multiplication, however, requires successive shift and addition operations which must be performed as many times as there are bits in the multiplier and is thus a more expensive operation. . Let us consider an input volume of the dimension (DVD_{V}DV​, DVD_{V}DV​, N) where DVD_{V}DV​ is the height and width of the volume and NNN is the number of channels. In the case of a standard RGB image N=3N = 3N=3 and for a gray-scale image N=1N = 1N=1. . Let us convolve V with a tensor of shape (DVD_{V}DV​, DVD_{V}DV​, N) or N tensors with the shape (DkD_{k}Dk​, DkD_{k}Dk​) which results in a volume GGG of shape (DGD_{G}DG​, DGD_{G}DG​, N). . Let us count the number of multiplication operations for this operation. . Number of multiplication operations for a single stride across a single channel = Dk∗DkD_{k} * D_{k}Dk​∗Dk​. . For M channels in the initial volume, the number of multiplication operations = (Dk)2∗M(D_{k})^{2} * M(Dk​)2∗M. . Sliding the kernel over a volume of (DVD_{V}DV​, DVD_{V}DV​, M), we get a tensor of shape (DGD_{G}DG​, DGD_{G}DG​, N). Hence the total number of multiplication operations for a single channel of the convolution kernel = (DG)2∗(Dk)2∗M(D_{G})^{2} * (D_{k})^{2} * M(DG​)2∗(Dk​)2∗M. . Since there are N channels in the convolutional kernel, this operation is repeated N times. Hence, the total number of multiplication operations for the above convolution operation = N∗(DG)2∗(Dk)2∗MN * (D_{G})^{2} * (D_{k})^{2} * MN∗(DG​)2∗(Dk​)2∗M. . Now, let us see how using an alternate form of the vanilla convolution operation, we can reduce time complexity. . Depthwise Separable Convolution . In the vanilla convolution operation all, the kernel is applied to all the channels of the input volume. However, Depthwise Separable Convolutions breaks down the whole operation into 2 steps: . Depthwise Convolution or the Filtering Stage | Pointwise Convolution or the Combination Stage | Depthwise Convolutions . Let us consider the same input volume (DVD_{V}DV​, DVD_{V}DV​, M) convolving with M (DKD_{K}DK​, DKD_{K}DK​) kernels. A single convolution with a single kernel gives a volume of (DGD_{G}DG​, DGD_{G}DG​, 1). Repeating this N times, we get N such tensors and stacking them up channel-wise, we get a single tensor of shape (DGD_{G}DG​, DGD_{G}DG​, M). . Now, the number of multiplication operations for a single kernel convolving over a single input channel = DK∗DKD_{K} * D_{K}DK​∗DK​. When the convolution is applied over an entire input volume . Let us now find the computational complexity for Depthwise Convolution. . The number of multiplication operations for the convolution of a single (DKD_{K}DK​, DKD_{K}DK​) kernel over a single stride over the input volume = (DK)2(D_{K})^{2}(DK​)2. . Since the output shape is (DGD_{G}DG​, DGD_{G}DG​), the number of multiplication operations for convolving over a single channel of the input image = (DG)2∗(DK)2(D_{G})^{2} * (D_{K})^{2}(DG​)2∗(DK​)2. . Since there are MMM number of kernels for convolving with MMM number of channels, the number of multiplication operations for Depthwise Convolution operation = M∗(DG)2∗(DK)2M * (D_{G})^{2} * (D_{K})^{2}M∗(DG​)2∗(DK​)2. . Pointwise Convolution . For Pointwise Convolution, we convolve the (DGD_{G}DG​, DGD_{G}DG​, M) volume with NNN kernels of (1, 1, MMM) producing the desired output of shape (DVD_{V}DV​, DVD_{V}DV​, N). . We will now find the computational complexity of the Pointwise Convolution operation. . For convolving a single kernel over a single stride of the input image, the number of multiplication operations = 1∗1∗M1 * 1 * M1∗1∗M = MMM. . For convolving a single kernel over a single channel of the input tensor producing a shape of (DGD_{G}DG​, DGD_{G}DG​), the number of multiplication operations = M∗(DG)2M * (D_{G})^{2}M∗(DG​)2. . For convolving NNN number of kernels over the whole of input tensor, the number of multiplication operations = N∗M∗(DG)2N * M * (D_{G})^{2}N∗M∗(DG​)2. . Comparing Vanilla Convolution with Depthwise Separable Convolution . Let us take the ratios between the Complexity of the Vanilla Convolution () operation and that of the Depthwise Separable Convolution operation. . convvanillaconvdsc=N∗(DG)2∗(DK)2∗MM∗(DG)2∗[(DK)2+N] frac{conv_{vanilla}}{conv_{dsc}} = frac{N * (D_{G})^{2} * (D_{K})^{2} * M}{M * (D_{G})^{2} * [(D_{K})^{2} + N]}convdsc​convvanilla​​=M∗(DG​)2∗[(DK​)2+N]N∗(DG​)2∗(DK​)2∗M​ . or, . convvanillaconvdsc=(DK)2∗M(DK)2+N frac{conv_{vanilla}}{conv_{dsc}} = frac{(D_{K})^{2} * M}{(D_{K})^{2} + N}convdsc​convvanilla​​=(DK​)2+N(DK​)2∗M​ . or, . convvanillaconvdsc=1(DK)2+1N frac{conv_{vanilla}}{conv_{dsc}} = frac{1}{(D_{K})^{2}} + frac{1}{N}convdsc​convvanilla​​=(DK​)21​+N1​ . Now, let us consider N=3N = 3N=3 and DK = [2 ** i for i in range(5, 11)] and visualize how the ratio varies. . Note that the ratio of Time Complexity of Vanilla Convolution to that of Depthwise Separable Convolution is always much less than 1 and it decreases with increasing Kernel Dimension, making it much faster compared to Vanilla Convolution. . Depthwise Separable Convolutions are widely used in building fast CNN architectures such as Xception, Mobilenet and Multi-modal Neural Networks. In the upcoming articles, we would discuss these two articles in detail. .",
            "url": "https://soumik12345.github.io/blog/cnn/computervision/convolution/deeplearning/2019/10/19/depthwise-seperable-convolution.html",
            "relUrl": "/cnn/computervision/convolution/deeplearning/2019/10/19/depthwise-seperable-convolution.html",
            "date": " • Oct 19, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://soumik12345.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://soumik12345.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}