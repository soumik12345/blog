{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://soumik12345.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Depthwise Separable Convolutions in Deep Learning",
            "content": "The Convolution operation is a widely used function in Functional Analysis, Image Processing Deep Learning. The convolution operation when applied on two functions f and g, produces a third function expressing how the shape of one is modified by the other. While it is immensely popular, especially in the domain of Deep Learning, the vanilla convolution operation is quite expensive computationally. Modern Neural Network architectures such as Xception and MobileNet use a special type of Convolution called Depthwise Separable Convolution to speed up training and inference, especially on Mobile and Embedded Devices. . The Vanilla Convolution Operation . The convolution function can be mathematically defined as the following: . (f⊛g)(t)=∫−∞∞f(τ)g(t−τ)dτ(f circledast g)(t) = int_{- infty}^{ infty} f( tau) g(t - tau) d tau(f⊛g)(t)=∫−∞∞​f(τ)g(t−τ)dτ . For all non-negative values of t (i.e, for all values of t such that t ∈ [0, ∞) ), we could truncate the limits of integration resulting in, . (f⊛g)(t)=∫0tf(τ)g(t−τ)dτ(f circledast g)(t) = int_{0}^{t} f( tau) g(t - tau) d tau(f⊛g)(t)=∫0t​f(τ)g(t−τ)dτ . It can also be defined as the overlap of two functions f and g as one slides over the other, performing a sum of products. . Source: https://en.wikipedia.org/wiki/Convolution Convolution as Sum of Products. Source: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1 Computational Complexity of Convolution . In order to decide the computational complexity of the convolutional operation, we would count the number of multiplication operations for a convolution. This is because the Binary Addition of two numbers may be performed in a single clock cycle using two registers with the inputs latched and a bunch of combinatorial logic gates. Binary multiplication, however, requires successive shift and addition operations which must be performed as many times as there are bits in the multiplier and is thus a more expensive operation. . Let us consider an input volume of the dimension (DVD_{V}DV​, DVD_{V}DV​, N) where DVD_{V}DV​ is the height and width of the volume and NNN is the number of channels. In the case of a standard RGB image N=3N = 3N=3 and for a gray-scale image N=1N = 1N=1. . Let us convolve V with a tensor of shape (DVD_{V}DV​, DVD_{V}DV​, N) or N tensors with the shape (DkD_{k}Dk​, DkD_{k}Dk​) which results in a volume GGG of shape (DGD_{G}DG​, DGD_{G}DG​, N). . Let us count the number of multiplication operations for this operation. . Number of multiplication operations for a single stride across a single channel = Dk∗DkD_{k} * D_{k}Dk​∗Dk​. . For M channels in the initial volume, the number of multiplication operations = (Dk)2∗M(D_{k})^{2} * M(Dk​)2∗M. . Sliding the kernel over a volume of (DVD_{V}DV​, DVD_{V}DV​, M), we get a tensor of shape (DGD_{G}DG​, DGD_{G}DG​, N). Hence the total number of multiplication operations for a single channel of the convolution kernel = (DG)2∗(Dk)2∗M(D_{G})^{2} * (D_{k})^{2} * M(DG​)2∗(Dk​)2∗M. . Since there are N channels in the convolutional kernel, this operation is repeated N times. Hence, the total number of multiplication operations for the above convolution operation = N∗(DG)2∗(Dk)2∗MN * (D_{G})^{2} * (D_{k})^{2} * MN∗(DG​)2∗(Dk​)2∗M. . Now, let us see how using an alternate form of the vanilla convolution operation, we can reduce time complexity. . Depthwise Separable Convolution . In the vanilla convolution operation all, the kernel is applied to all the channels of the input volume. However, Depthwise Separable Convolutions breaks down the whole operation into 2 steps: . Depthwise Convolution or the Filtering Stage | Pointwise Convolution or the Combination Stage | Depthwise Convolutions . Let us consider the same input volume (DVD_{V}DV​, DVD_{V}DV​, M) convolving with M (DKD_{K}DK​, DKD_{K}DK​) kernels. A single convolution with a single kernel gives a volume of (DGD_{G}DG​, DGD_{G}DG​, 1). Repeating this N times, we get N such tensors and stacking them up channel-wise, we get a single tensor of shape (DGD_{G}DG​, DGD_{G}DG​, M). . Now, the number of multiplication operations for a single kernel convolving over a single input channel = DK∗DKD_{K} * D_{K}DK​∗DK​. When the convolution is applied over an entire input volume . Let us now find the computational complexity for Depthwise Convolution. . The number of multiplication operations for the convolution of a single (DKD_{K}DK​, DKD_{K}DK​) kernel over a single stride over the input volume = (DK)2(D_{K})^{2}(DK​)2. . Since the output shape is (DGD_{G}DG​, DGD_{G}DG​), the number of multiplication operations for convolving over a single channel of the input image = (DG)2∗(DK)2(D_{G})^{2} * (D_{K})^{2}(DG​)2∗(DK​)2. . Since there are MMM number of kernels for convolving with MMM number of channels, the number of multiplication operations for Depthwise Convolution operation = M∗(DG)2∗(DK)2M * (D_{G})^{2} * (D_{K})^{2}M∗(DG​)2∗(DK​)2. . Pointwise Convolution . For Pointwise Convolution, we convolve the (DGD_{G}DG​, DGD_{G}DG​, M) volume with NNN kernels of (1, 1, MMM) producing the desired output of shape (DVD_{V}DV​, DVD_{V}DV​, N). . We will now find the computational complexity of the Pointwise Convolution operation. . For convolving a single kernel over a single stride of the input image, the number of multiplication operations = 1∗1∗M1 * 1 * M1∗1∗M = MMM. . For convolving a single kernel over a single channel of the input tensor producing a shape of (DGD_{G}DG​, DGD_{G}DG​), the number of multiplication operations = M∗(DG)2M * (D_{G})^{2}M∗(DG​)2. . For convolving NNN number of kernels over the whole of input tensor, the number of multiplication operations = N∗M∗(DG)2N * M * (D_{G})^{2}N∗M∗(DG​)2. . Comparing Vanilla Convolution with Depthwise Separable Convolution . Let us take the ratios between the Complexity of the Vanilla Convolution () operation and that of the Depthwise Separable Convolution operation. . convvanillaconvdsc=N∗(DG)2∗(DK)2∗MM∗(DG)2∗[(DK)2+N] frac{conv_{vanilla}}{conv_{dsc}} = frac{N * (D_{G})^{2} * (D_{K})^{2} * M}{M * (D_{G})^{2} * [(D_{K})^{2} + N]}convdsc​convvanilla​​=M∗(DG​)2∗[(DK​)2+N]N∗(DG​)2∗(DK​)2∗M​ . or, . convvanillaconvdsc=(DK)2∗M(DK)2+N frac{conv_{vanilla}}{conv_{dsc}} = frac{(D_{K})^{2} * M}{(D_{K})^{2} + N}convdsc​convvanilla​​=(DK​)2+N(DK​)2∗M​ . or, . convvanillaconvdsc=1(DK)2+1N frac{conv_{vanilla}}{conv_{dsc}} = frac{1}{(D_{K})^{2}} + frac{1}{N}convdsc​convvanilla​​=(DK​)21​+N1​ . Now, let us consider N=3N = 3N=3 and DK = [2 ** i for i in range(5, 11)] and visualize how the ratio varies. . Note that the ratio of Time Complexity of Vanilla Convolution to that of Depthwise Separable Convolution is always much less than 1 and it decreases with increasing Kernel Dimension, making it much faster compared to Vanilla Convolution. . Depthwise Separable Convolutions are widely used in building fast CNN architectures such as Xception, Mobilenet and Multi-modal Neural Networks. In the upcoming articles, we would discuss these two articles in detail. .",
            "url": "https://soumik12345.github.io/blog/cnn/computervision/convolution/deeplearning/2019/10/19/depthwise-seperable-convolution.html",
            "relUrl": "/cnn/computervision/convolution/deeplearning/2019/10/19/depthwise-seperable-convolution.html",
            "date": " • Oct 19, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://soumik12345.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://soumik12345.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}